{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN classifier for microscopy images\n",
    "\n",
    "Step 1 image processing\n",
    "\n",
    "\n",
    "\n",
    "Different options are included. \n",
    "\n",
    "1. Downsample\n",
    "2. gridcrop \n",
    "3. cell crop\n",
    "\n",
    "Filter images first\n",
    "1. Quality control\n",
    "2. Filter by neuron count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "\n",
    "# read in quality control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic processing Downsample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 create the model and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create_model_original.py\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Used to create the original model architecture\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "# create_model_original.py\n",
    "#\n",
    "# Used to create the original model architecture\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "# model.save('models/model_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "#\n",
    "# Used to train models with data generator\n",
    "#\n",
    "# train_path - Paths for preprocessed images\n",
    "# model_start - Path for model to begin training with 'model_original' (SavedModel format)\n",
    "# model_name - Path to save newly trained model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_set_name = 'XCL_NPC_2_3'\n",
    "model_start_name = 'model_original'\n",
    "model_name = 'model_XCL_NPC_2_3'\n",
    "steps_per_epoch = 64\n",
    "max_epochs = 5000\n",
    "early_stopping_patience = 200\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "train_path = 'data/' + train_set_name + '/train_set'\n",
    "model_start_path = 'models/' + model_start_name\n",
    "model_path = 'models/' + model_name\n",
    "\n",
    "# Create data generators\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255.0, validation_split=0.2)\n",
    "train_gen = datagen.flow_from_directory(train_path, class_mode='categorical', batch_size=64, target_size=(64, 64), shuffle=True)\n",
    "val_gen = datagen.flow_from_directory(train_path, class_mode='categorical', batch_size=64, target_size=(64, 64),  subset='validation')\n",
    "\n",
    "\n",
    "# Load saved model and display the model's architecture\n",
    "model = load_model(model_start_path)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Pregenerate folder for end model\n",
    "model.save(model_path)\n",
    "\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=early_stopping_patience),\n",
    "             ModelCheckpoint(filepath='models/' + model_path + '/best_weights.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "\n",
    "# Model Training\n",
    "history = model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=callbacks,  # Early stopping\n",
    "        validation_data=val_gen,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "# Save the current model after training\n",
    "model.save(model_path)\n",
    "\n",
    "# List all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Create plots for accuracy and loss during training and save in model folder\n",
    "# Plot accuracy history and save it into model directory\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(model_path + '/training_accuracy.png')\n",
    "plt.clf()\n",
    "\n",
    "# Plot loss history and save it into model directory\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(model_path + '/training_loss.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "684302c300eff0b62fe689c5a68997e188347b7361bba76c4d20b295dbaf8d1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
